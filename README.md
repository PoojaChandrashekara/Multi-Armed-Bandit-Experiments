# Multi-Armed Bandit Experiments

This repository contains Python code for exploring and comparing different Multi-Armed Bandit (MAB) algorithms. It includes implementations for:

- Epsilon-Greedy with various exploration strategies
- Optimistic Initial Values
- Gradient Bandit

## Key Features

- Visualizes the performance of each algorithm in terms of accumulated reward.
- Analyzes the impact of different hyperparameters on algorithm behavior.
- Compares the convergence rates and final Q-value estimates of different algorithms.

## Project Structure

- `README.md`: This file provides an overview of the project.
- `requirements.txt`: Lists the required Python libraries.
- `epsilon_greedy.py`: Contains code for the Epsilon-Greedy algorithm.


## Usage

1. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
